{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "08_collab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QxqZwfttJJ4r",
        "MgZykdx-JJ4s",
        "rvJSVISKJJ4t",
        "KkuVF6RyJJ4u",
        "V3w9I8DyJJ4u",
        "S6-3ssaWJJ4v",
        "Xdbipf6fJJ4v",
        "Z8E4lXGkJJ4w",
        "_5mt2XahJJ4w",
        "d6ewEit8JJ4w",
        "QLcQS4igJJ4w",
        "u53a92AmJJ4x"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq8PEoPyJQft",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9c41a98-c9b9-4e3a-ddef-26e9989d2a00"
      },
      "source": [
        "!pip install -U fastbook torchtext==0.8.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastbook\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/ff/66f16fb9ceb45646e59a38ad5eb0f05fbd6524c20d9c4a2c922cdcd2955b/fastbook-0.0.16-py3-none-any.whl (720kB)\n",
            "\u001b[K     |████████████████████████████████| 727kB 10.2MB/s \n",
            "\u001b[?25hCollecting torchtext==0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/80/046f0691b296e755ae884df3ca98033cb9afcaf287603b2b7999e94640b8/torchtext-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 26.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.7/dist-packages (from fastbook) (19.3.1)\n",
            "Collecting nbdev>=0.2.38\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/c8/e2fba530b84a770373a106e4828ea83df62104b9694e367d169e07ea484f/nbdev-1.1.14-py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
            "\u001b[?25hCollecting fastai>=2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/53/edf39e15b7ec5e805a0b6f72adbe48497ebcfa009a245eca7044ae9ee1c6/fastai-2.3.0-py3-none-any.whl (193kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 52.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from fastbook) (1.1.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 55.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from fastbook) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: ipywidgets in /usr/local/lib/python3.7/dist-packages (from fastbook) (7.6.3)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from fastbook) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (1.19.5)\n",
            "Collecting torch==1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 23kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: ipykernel in /usr/local/lib/python3.7/dist-packages (from nbdev>=0.2.38->fastbook) (4.10.1)\n",
            "Collecting ghapi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/bf/4085cf4e516591f76b3b367c12b944c85b9321c64590ee030f181d656845/ghapi-0.1.16-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 38kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: jupyter-client<=6.1.12 in /usr/local/lib/python3.7/dist-packages (from nbdev>=0.2.38->fastbook) (5.3.5)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from nbdev>=0.2.38->fastbook) (3.13)\n",
            "Collecting fastrelease\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/66/685d5cbd0534395a209ad04afb1573f03467ef3b430b8ee1fec24c332d0c/fastrelease-0.1.11-py3-none-any.whl\n",
            "Collecting fastcore>=1.3.19\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/98/60404e2817cff113a6ae4023bc1772e23179408fdf7857fa410551758dfe/fastcore-1.3.19-py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: nbformat>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from nbdev>=0.2.38->fastbook) (5.1.2)\n",
            "Requirement already satisfied, skipping upgrade: nbconvert<6 in /usr/local/lib/python3.7/dist-packages (from nbdev>=0.2.38->fastbook) (5.6.1)\n",
            "Requirement already satisfied, skipping upgrade: jupyter in /usr/local/lib/python3.7/dist-packages (from nbdev>=0.2.38->fastbook) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.1->fastbook) (7.1.2)\n",
            "Collecting torchvision<0.9,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/df/969e69a94cff1c8911acb0688117f95e1915becc1e01c73e7960a2c76ec8/torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 246kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.1->fastbook) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from fastai>=2.1->fastbook) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: spacy<3 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.1->fastbook) (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai>=2.1->fastbook) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai>=2.1->fastbook) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastbook) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastbook) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastbook) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->fastbook) (5.5.0)\n",
            "Requirement already satisfied, skipping upgrade: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->fastbook) (5.0.5)\n",
            "Requirement already satisfied, skipping upgrade: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->fastbook) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->fastbook) (3.5.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastbook) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastbook) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastbook) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastbook) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->torchtext==0.8.1) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->nbdev>=0.2.38->fastbook) (5.1.1)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<=6.1.12->nbdev>=0.2.38->fastbook) (4.7.1)\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<=6.1.12->nbdev>=0.2.38->fastbook) (22.0.3)\n",
            "Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4.0->nbdev>=0.2.38->fastbook) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4.0->nbdev>=0.2.38->fastbook) (2.6.0)\n",
            "Requirement already satisfied, skipping upgrade: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev>=0.2.38->fastbook) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev>=0.2.38->fastbook) (1.4.3)\n",
            "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev>=0.2.38->fastbook) (0.3)\n",
            "Requirement already satisfied, skipping upgrade: jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev>=0.2.38->fastbook) (2.11.3)\n",
            "Requirement already satisfied, skipping upgrade: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev>=0.2.38->fastbook) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev>=0.2.38->fastbook) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev>=0.2.38->fastbook) (0.8.4)\n",
            "Requirement already satisfied, skipping upgrade: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev>=0.2.38->fastbook) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev>=0.2.38->fastbook) (5.3.1)\n",
            "Requirement already satisfied, skipping upgrade: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev>=0.2.38->fastbook) (5.0.3)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev>=0.2.38->fastbook) (5.2.0)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai>=2.1->fastbook) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai>=2.1->fastbook) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai>=2.1->fastbook) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai>=2.1->fastbook) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai>=2.1->fastbook) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai>=2.1->fastbook) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai>=2.1->fastbook) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai>=2.1->fastbook) (54.2.0)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai>=2.1->fastbook) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai>=2.1->fastbook) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.1->fastbook) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.1->fastbook) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai>=2.1->fastbook) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->fastbook) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->fastbook) (1.0.18)\n",
            "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->fastbook) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->fastbook) (4.8.0)\n",
            "Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->fastbook) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->fastbook) (0.7.5)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.4->nbconvert<6->nbdev>=0.2.38->fastbook) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert<6->nbdev>=0.2.38->fastbook) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nbdev>=0.2.38->fastbook) (1.5.0)\n",
            "Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nbdev>=0.2.38->fastbook) (0.9.3)\n",
            "Requirement already satisfied, skipping upgrade: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->nbdev>=0.2.38->fastbook) (1.9.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3->fastai>=2.1->fastbook) (3.8.1)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->fastbook) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->fastbook) (0.7.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3->fastai>=2.1->fastbook) (3.4.1)\n",
            "Installing collected packages: fastcore, ghapi, fastrelease, nbdev, torch, torchvision, fastai, sentencepiece, fastbook, torchtext\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "  Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "  Found existing installation: torchtext 0.9.1\n",
            "    Uninstalling torchtext-0.9.1:\n",
            "      Successfully uninstalled torchtext-0.9.1\n",
            "Successfully installed fastai-2.3.0 fastbook-0.0.16 fastcore-1.3.19 fastrelease-0.1.11 ghapi-0.1.16 nbdev-1.1.14 sentencepiece-0.1.95 torch-1.7.1 torchtext-0.8.1 torchvision-0.8.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "fastai",
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoDQ6ZRHJJ4d"
      },
      "source": [
        "# Collaborative Filtering Deep Dive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrU3sTbBJJ4g"
      },
      "source": [
        "Recommendation systems use *collaborative filtering* to recommend users products that other similar users have liked. Collaborative filtering does not require the model to know the exact properties of an item to recommend it to others. For example, Netflix does not need to know the genres of movies that one user tends to watch; it only needs to know that other users who have watched the same movies also like watching some other movies. These \"some other movies\" are then recommended to that one user, since their watch histories are similar.\n",
        "\n",
        "These systems involve *latent factors*, some underlying concept of what the movies are categorized in, yet not specifically added to a column in a data table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqZWWjVjJJ4h"
      },
      "source": [
        "## A First Look at the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7wTE7pMJJ4h"
      },
      "source": [
        "Import stuff and get the MovieLens dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmj105lpJJ4i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "98215384-c4c2-4b7e-9480-d5c67e02cc87"
      },
      "source": [
        "from fastai.collab import *\n",
        "from fastai.tabular.all import *\n",
        "path = untar_data(URLs.ML_100k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9Y8NxcBJJ4i"
      },
      "source": [
        "The data table is contained in the file *u.data*. The data is tab-separated and the columns are *user*, *movie*, *rating*, and *timestamp*. We use Pandas to read in the data, and use a subset of size 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6ruhcSdJJ4j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2065efaf-9e50-4b32-8cbf-4356f65760c2"
      },
      "source": [
        "ratings = pd.read_csv(path/'u.data', delimiter='\\t', header=None,\n",
        "                      names=['user', 'movie', 'rating', 'timestamp'])\n",
        "\n",
        "ratings = ratings[:100]\n",
        "ratings.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>movie</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user  movie  rating  timestamp\n",
              "0   196    242       3  881250949\n",
              "1   186    302       3  891717742\n",
              "2    22    377       1  878887116\n",
              "3   244     51       2  880606923\n",
              "4   166    346       1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WK1ZCKbJJ4k"
      },
      "source": [
        "Below is a small example of how we can use numbers between -1 and 1 to represent how much of something a movie is. The arrays below contain 3 numbers: the first represents how sci-fi related the movie is (closer to 1 means more sci-fi); the second represents how action-based it is (closer to 1 means more action-based); and the third represents how old it is (closer to 1 means very old).\n",
        "\n",
        "We can represent these properties in user arrays too, based on how much they like these categories/properties. User1 really likes sci-fi, action, and newer movies, so we can calculate how much the user may like *The Last Skywalker* using the *dot product* (multiplying the elements of two vectors together, then summing the result)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syKsYHd5JJ4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a8844e8-3f8d-432c-857f-927351ce65cf"
      },
      "source": [
        "last_skywalker = np.array([0.98,0.9,-0.9])\n",
        "user1 = np.array([0.9,0.8,-0.6])\n",
        "(user1 * last_skywalker).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.1420000000000003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEicGI7rJJ4l"
      },
      "source": [
        "If we use this scale for *Casablanca*, we can see that user1 is predicted to not like this movie as much:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqTt6J7hJJ4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82704f3e-725d-41c3-8007-391ed3a3b469"
      },
      "source": [
        "casablanca = np.array([-0.99,-0.3,0.8])\n",
        "(user1 * casablanca).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.611"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WKHPfm0JJ4m"
      },
      "source": [
        "## Learning the Latent Factors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59tcNA6gJJ4m"
      },
      "source": [
        "We will use the latent factors as the parameters in our model. The latent factors are the underlying properties - in the movie example, how much action a user liked or how much action a movie contained were considered latent factors. We (1) randomly initialize these. We can then (2) just use the dot product to calculate how likely a user is to like a certain movie. Finally, (3) we can calculate the loss.\n",
        "\n",
        "The loss will be used when the model calculates a prediction to see whether or not a user will like a movie on a numerical scale. This prediction will be compared to what the user actually rated the movie, which results in the loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V6VCUBEJJ4n"
      },
      "source": [
        "## Creating the DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIAOC7k1KD5H"
      },
      "source": [
        "`u.item` contains the table linking movies to their IDs; we want to see the movie title instead, so we grab that information:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdXuFAtVJJ4n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "05356184-c163-48e7-ea37-af45c7178bc0"
      },
      "source": [
        "movies = pd.read_csv(path/'u.item', delimiter='|', encoding='latin-1',\n",
        "                     usecols=(0,1), names=('movie', 'title'), header=None)\n",
        "movies.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>GoldenEye (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Four Rooms (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Get Shorty (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Copycat (1995)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movie              title\n",
              "0      1   Toy Story (1995)\n",
              "1      2   GoldenEye (1995)\n",
              "2      3  Four Rooms (1995)\n",
              "3      4  Get Shorty (1995)\n",
              "4      5     Copycat (1995)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz2retVzJpme"
      },
      "source": [
        "Merge `movies` and `ratings` together to get the user ratings by title:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV160XQqJJ4n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "94845695-dfe4-4969-9280-9d62c74d9a39"
      },
      "source": [
        "ratings = ratings.merge(movies)\n",
        "ratings.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>movie</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "      <td>Kolya (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "      <td>L.A. Confidential (1997)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "      <td>Heavyweights (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "      <td>Legends of the Fall (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "      <td>Jackie Brown (1997)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user  movie  rating  timestamp                       title\n",
              "0   196    242       3  881250949                Kolya (1996)\n",
              "1   186    302       3  891717742    L.A. Confidential (1997)\n",
              "2    22    377       1  878887116         Heavyweights (1994)\n",
              "3   244     51       2  880606923  Legends of the Fall (1994)\n",
              "4   166    346       1  886397596         Jackie Brown (1997)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVcFtESTK9Kx"
      },
      "source": [
        "Create `DataLoaders` object. We specify a batch size of 64, using the ratings data. The `CollabDataLoaders` defaults to taking the first three columns (user, item (movie), and rating). However, we want the movie title rather than the ID, so we specify `item_name` as \"title.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU46elBhJJ4n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "42fc2c2b-3f72-4850-88aa-310e26fb2cc5"
      },
      "source": [
        "dls = CollabDataLoaders.from_df(ratings, item_name='title', bs=64)\n",
        "dls.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>title</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>62</td>\n",
              "      <td>African Queen, The (1951)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>305</td>\n",
              "      <td>Grease (1978)</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>243</td>\n",
              "      <td>Mr. Holland's Opus (1995)</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20</td>\n",
              "      <td>Scream (1996)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>290</td>\n",
              "      <td>Sound of Music, The (1965)</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>138</td>\n",
              "      <td>Brothers McMullen, The (1995)</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>157</td>\n",
              "      <td>Sabrina (1995)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>194</td>\n",
              "      <td>Sabrina (1995)</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>99</td>\n",
              "      <td>Get Shorty (1995)</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>French Twist (Gazon maudit) (1995)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uglgsbz3M8O2"
      },
      "source": [
        "The dictionary `dls.classes` contains the titles and user IDs in matrices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQYmdncyJJ4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "346d1af4-f7b7-4ec3-fbfa-bf3c91199409"
      },
      "source": [
        "dls.classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'title': ['#na#', 'Adventures of Priscilla, Queen of the Desert, The (1994)', 'African Queen, The (1951)', 'Age of Innocence, The (1993)', 'Aladdin (1992)', 'Angels and Insects (1995)', 'Backbeat (1993)', 'Batman (1989)', 'Batman Forever (1995)', 'Bean (1997)', 'Beautiful Thing (1996)', 'Ben-Hur (1959)', 'Birdcage, The (1996)', 'Boot, Das (1981)', 'Broken Arrow (1996)', 'Brothers McMullen, The (1995)', 'Casper (1995)', 'Chasing Amy (1997)', 'City of Lost Children, The (1995)', 'Con Air (1997)', 'Conan the Barbarian (1981)', 'Cop Land (1997)', 'Copycat (1995)', 'Crumb (1994)', 'Curdled (1996)', 'Dangerous Minds (1995)', 'Dead Poets Society (1989)', 'Die Hard (1988)', 'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)', 'E.T. the Extra-Terrestrial (1982)', 'Endless Summer 2, The (1994)', 'Evil Dead II (1987)', 'Fantasia (1940)', 'Fargo (1996)', 'Fly Away Home (1996)', 'French Twist (Gazon maudit) (1995)', 'Get Shorty (1995)', 'Grease (1978)', 'Grosse Pointe Blank (1997)', 'Heavyweights (1994)', 'House Arrest (1996)', 'Hunt for Red October, The (1990)', 'Jackie Brown (1997)', 'Jaws (1975)', 'Jean de Florette (1986)', 'Jerry Maguire (1996)', 'Jungle Book, The (1994)', 'Just Cause (1995)', 'Kiss the Girls (1997)', 'Kolya (1996)', 'L.A. Confidential (1997)', 'Last of the Mohicans, The (1992)', 'Legends of the Fall (1994)', 'Man Without a Face, The (1993)', 'Men in Black (1997)', \"Miller's Crossing (1990)\", \"Monty Python's Life of Brian (1979)\", \"Mr. Holland's Opus (1995)\", 'Murder at 1600 (1997)', 'Naked Gun 33 1/3: The Final Insult (1994)', 'Nightmare on Elm Street, A (1984)', 'North by Northwest (1959)', 'Old Yeller (1957)', 'Only You (1994)', 'Outbreak (1995)', 'Rear Window (1954)', 'Remains of the Day, The (1993)', 'Restoration (1995)', 'Return of the Jedi (1983)', 'Right Stuff, The (1983)', \"Romy and Michele's High School Reunion (1997)\", 'Sabrina (1954)', 'Sabrina (1995)', 'Scream (1996)', 'Sense and Sensibility (1995)', 'Seven Years in Tibet (1997)', 'Silence of the Lambs, The (1991)', 'Sleepless in Seattle (1993)', 'Sound of Music, The (1965)', 'Speechless (1994)', 'Star Trek III: The Search for Spock (1984)', 'Star Trek: First Contact (1996)', 'Sting, The (1973)', 'Sword in the Stone, The (1963)', 'Tales from the Hood (1995)', 'Taxi Driver (1976)', 'That Darn Cat! (1965)', 'This Is Spinal Tap (1984)', 'To Kill a Mockingbird (1962)', 'To Wong Foo, Thanks for Everything! Julie Newmar (1995)', 'Toy Story (1995)', 'Trigger Effect, The (1996)', 'Truth About Cats & Dogs, The (1996)', 'Twister (1996)', 'Wings of Desire (1987)', 'Young Guns (1988)'],\n",
              " 'user': ['#na#', 6, 7, 8, 10, 13, 20, 38, 42, 50, 57, 59, 60, 62, 63, 72, 81, 87, 95, 97, 99, 102, 115, 119, 127, 135, 138, 157, 162, 166, 167, 181, 189, 194, 196, 201, 210, 222, 223, 224, 225, 241, 242, 243, 244, 246, 251, 253, 254, 260, 267, 276, 279, 284, 286, 287, 290, 291, 292, 293, 298, 299, 301, 303, 305, 308]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8mZ26cJNhAN"
      },
      "source": [
        "Get the number of users, number of movies, and number of latent factors. We then create `n_users` simple matrices, which contain the randomly-initialized activations (one for each factor)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qicgp1NBJJ4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39b4994e-277c-4280-c38a-541c88de1627"
      },
      "source": [
        "n_users  = len(dls.classes['user'])\n",
        "n_movies = len(dls.classes['title'])\n",
        "n_factors = 5\n",
        "\n",
        "user_factors = torch.randn(n_users, n_factors)\n",
        "movie_factors = torch.randn(n_movies, n_factors)\n",
        "\n",
        "user_factors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.1402e+00, -8.4710e-01,  7.8952e-01,  3.5393e-01,  2.7922e-01],\n",
              "        [ 4.8255e-01,  1.2134e+00,  6.5220e-01,  8.9973e-01,  4.6080e-02],\n",
              "        [-4.9669e-01, -8.2709e-01, -1.5043e+00, -1.4431e+00, -4.7567e-01],\n",
              "        [-9.1052e-01,  1.5512e+00, -2.0908e+00,  2.4692e-01,  7.7302e-01],\n",
              "        [ 8.3420e-02, -7.9846e-02, -1.8727e-01, -3.6270e-01, -5.7868e-01],\n",
              "        [ 1.9277e+00,  1.4729e+00, -5.2919e-01,  6.3958e-02,  4.1789e-01],\n",
              "        [-8.3687e-01,  7.0918e-02,  2.6778e-02, -1.6565e-01,  6.2842e-01],\n",
              "        [-5.3191e-01,  5.2061e-01, -1.3808e+00, -1.9204e-01,  2.4967e-02],\n",
              "        [ 1.5520e-01, -7.5036e-01, -4.0835e-01, -1.3841e+00,  5.5969e-01],\n",
              "        [-1.7786e+00, -2.1356e-01, -8.1852e-01,  4.6667e-01, -1.7879e+00],\n",
              "        [ 8.0190e-01,  1.1741e-01,  4.7339e-01, -9.8263e-01,  9.5627e-01],\n",
              "        [ 5.8329e-01,  1.7201e+00,  1.1283e+00, -1.2653e+00,  7.5348e-02],\n",
              "        [-1.0841e+00,  3.2637e-01, -4.6441e-01,  9.7867e-01, -8.3603e-01],\n",
              "        [ 1.2445e-01,  2.9038e-01, -7.5124e-01, -3.5752e-02, -1.1628e+00],\n",
              "        [-7.4290e-01,  1.0925e+00,  2.2571e+00,  2.2402e-01, -9.5747e-01],\n",
              "        [ 2.9950e-01, -5.2802e-01,  4.2524e-01,  5.2847e-01, -5.6701e-01],\n",
              "        [ 2.0064e+00,  1.1351e+00, -4.3376e-01,  1.4240e-01, -1.0871e+00],\n",
              "        [ 1.3664e+00, -4.1475e-01,  8.2143e-01, -1.1460e+00,  8.7058e-01],\n",
              "        [ 1.5436e+00, -8.3261e-02,  8.1035e-01, -8.0350e-01,  1.7235e+00],\n",
              "        [ 3.4066e-01, -1.2250e+00,  1.3093e+00, -9.3956e-01,  2.9339e-01],\n",
              "        [ 7.6823e-01,  2.2958e-01,  3.3870e-02,  1.9458e+00, -2.8739e-01],\n",
              "        [ 7.4037e-01,  1.1734e-01,  3.7308e-01,  1.6945e+00, -2.4059e+00],\n",
              "        [-1.3830e+00, -1.5216e-01, -2.0476e+00, -1.4916e+00,  3.6685e-02],\n",
              "        [ 8.1843e-01,  3.7337e-01, -2.1724e-01, -1.1618e-01, -8.7383e-01],\n",
              "        [-2.4287e-01, -6.4501e-01,  2.7542e-01, -1.4974e-01,  2.1206e-01],\n",
              "        [ 1.0136e+00,  4.8032e-01, -1.9993e+00, -6.6516e-01,  7.4596e-01],\n",
              "        [ 2.3042e+00, -5.1182e-01,  7.8027e-01, -1.3823e+00,  2.7362e-01],\n",
              "        [-7.9270e-01,  1.0591e-01,  4.1511e-01, -2.4493e-01,  7.8508e-01],\n",
              "        [ 9.3905e-01, -7.9231e-01,  1.1127e+00, -1.0422e+00,  7.5700e-01],\n",
              "        [ 1.5183e-01,  1.0389e+00,  1.1503e-01, -2.8518e-01, -4.8634e-01],\n",
              "        [ 1.2510e+00,  6.4748e-01,  1.1292e+00,  6.8707e-01, -8.3293e-01],\n",
              "        [-3.7985e-01,  1.5218e+00,  3.9509e-01, -3.8930e-02,  1.2251e+00],\n",
              "        [ 5.0917e-03, -1.0443e+00, -3.3895e-01, -8.4945e-01, -1.6138e+00],\n",
              "        [ 6.1828e-01, -6.0612e-01, -1.2312e-01,  1.2776e+00,  1.3491e+00],\n",
              "        [ 2.0526e-01,  6.6853e-01,  1.1109e-01, -2.4233e-03,  1.0170e+00],\n",
              "        [ 5.6872e-01,  1.2357e-01, -1.2677e-02,  1.2314e+00,  1.3571e+00],\n",
              "        [ 4.6539e-01,  4.1989e-01, -7.7657e-01, -3.4223e+00,  8.0029e-01],\n",
              "        [ 3.8692e-01,  1.0281e+00, -2.3078e-01, -3.0090e-01,  1.1758e-01],\n",
              "        [-1.1299e+00, -3.0072e-01,  1.2586e+00, -1.0716e+00, -1.4114e+00],\n",
              "        [ 9.5204e-02,  2.4846e-01,  1.8700e-01, -3.9979e-01,  3.2501e-01],\n",
              "        [-2.6389e-01,  3.7617e-02, -7.2113e-03, -1.2712e+00,  2.6950e+00],\n",
              "        [ 3.5914e-01,  4.0412e-01,  4.6027e-01,  9.0017e-02,  1.1611e+00],\n",
              "        [ 3.5149e-01, -1.4340e+00,  5.1874e-01, -5.3690e-01,  1.2788e+00],\n",
              "        [ 1.6839e+00,  5.3154e-02,  1.0956e+00,  1.3863e+00,  6.6138e-01],\n",
              "        [ 4.8485e-01, -1.5136e+00, -7.0865e-01, -1.5387e+00, -5.3395e-01],\n",
              "        [ 1.2610e-01, -1.1593e+00,  1.9573e+00, -4.0198e-01, -3.7912e-01],\n",
              "        [ 7.2237e-01,  1.6808e+00,  4.6183e-01, -6.8678e-01, -1.8258e-01],\n",
              "        [-8.5244e-01,  9.2191e-01, -4.6695e-02,  1.6051e-01, -1.5718e-01],\n",
              "        [ 5.0681e-01,  2.4222e-01, -7.1761e-01,  6.2625e-01, -4.0124e-01],\n",
              "        [ 7.2168e-01,  1.4876e+00,  6.3203e-01, -7.9139e-01,  1.4427e+00],\n",
              "        [ 2.7511e-01,  1.2674e+00,  1.9917e-01,  1.6617e-01,  5.4253e-01],\n",
              "        [ 3.2412e-01, -1.9851e+00, -1.8709e+00, -4.1461e-01,  5.1957e-01],\n",
              "        [-9.9556e-01, -4.2466e-01,  1.9329e+00,  4.9019e-01, -8.4482e-01],\n",
              "        [ 8.8356e-02, -6.2086e-01,  1.6424e-01,  9.4550e-01,  1.3900e+00],\n",
              "        [-3.7481e-01,  1.9705e-01,  7.8588e-01,  3.4653e-01, -3.0228e-02],\n",
              "        [-4.2918e-01, -1.0556e+00,  7.3449e-01, -2.3902e+00, -9.8991e-01],\n",
              "        [ 1.2483e+00, -6.7326e-01,  2.9560e-01, -4.0229e-01,  3.7617e-01],\n",
              "        [-1.6361e+00, -8.1902e-01,  8.5004e-01, -9.5073e-02, -2.4155e-01],\n",
              "        [ 1.7075e+00,  5.0075e-01, -1.0611e+00, -7.0770e-01,  1.1661e+00],\n",
              "        [ 8.4614e-01, -2.5614e-02, -9.4868e-01,  5.3034e-01, -8.9805e-01],\n",
              "        [ 1.4563e+00, -8.4735e-01, -7.3288e-01, -6.5302e-01,  2.0201e+00],\n",
              "        [ 1.1041e+00,  8.7875e-01, -6.3207e-01, -2.2122e-01, -1.4614e+00],\n",
              "        [-1.8254e+00,  2.0852e+00, -1.3774e-01, -1.1671e+00,  4.5374e-01],\n",
              "        [-8.0291e-01,  2.2912e-01, -2.4567e-01,  2.8119e-01,  1.5803e+00],\n",
              "        [-1.3750e+00, -1.1013e+00,  5.0891e-01, -8.0585e-01, -5.0242e-01],\n",
              "        [ 1.0717e+00, -2.4326e-01,  7.5546e-03,  1.1524e+00, -1.3983e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgnYU6H1OYVU"
      },
      "source": [
        "Create a one-hot-encoded vector representing the index 3 (where all values in the vector are 0 except for index 3). The size of the vector is `n_users`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KLaAKk0JJ4o"
      },
      "source": [
        "one_hot_3 = one_hot(3, n_users).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUIkOEezOtJu"
      },
      "source": [
        "Take the transpose of the `user_factors` matrix and do matrix multiplication with `one_hot_3`. The size of the `user_factors` transpose is 5x`n_users` and the size of `one_hot_3` is `n_users`x1, so we will end up with a 5x1 matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy0NIpyGJJ4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca3d9e7d-952a-4b8c-8412-74eec7dc9078"
      },
      "source": [
        "user_factors.t() @ one_hot_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9105,  1.5512, -2.0908,  0.2469,  0.7730])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQWLxqbpPucZ"
      },
      "source": [
        "Doing this matrix multiplication is the same as indexing into `user_factors` at index 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAn5E0fFJJ4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2422ade6-50f4-411b-cd91-fd76e4bded60"
      },
      "source": [
        "user_factors[3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9105,  1.5512, -2.0908,  0.2469,  0.7730])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJGNXoDpQzbS"
      },
      "source": [
        "Embedding matrix is mulitplied by the one-hot-encoded matrix to get the desired vector. This is the same as indexing directly into the embedding matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SylIRB6lJJ4p"
      },
      "source": [
        "## Collaborative Filtering from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZgtVC9ZJJ4p"
      },
      "source": [
        "class Example:\n",
        "    def __init__(self, a): self.a = a\n",
        "    def say(self,x): return f'Hello {self.a}, {x}.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcMOO_blJJ4p"
      },
      "source": [
        "class DotProduct(Module):\n",
        "    def __init__(self, n_users, n_movies, n_factors):\n",
        "        self.user_factors = Embedding(n_users, n_factors)\n",
        "        self.movie_factors = Embedding(n_movies, n_factors)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        users = self.user_factors(x[:,0])\n",
        "        movies = self.movie_factors(x[:,1])\n",
        "        return (users * movies).sum(dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niBVrgCgJJ4q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li2czJxQJJ4q"
      },
      "source": [
        "model = DotProduct(n_users, n_movies, 50)\n",
        "learn = Learner(dls, model, loss_func=MSELossFlat())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-Qt8qDoJJ4q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL-YWe78JJ4q"
      },
      "source": [
        "class DotProduct(Module):\n",
        "    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
        "        self.user_factors = Embedding(n_users, n_factors)\n",
        "        self.movie_factors = Embedding(n_movies, n_factors)\n",
        "        self.y_range = y_range\n",
        "        \n",
        "    def forward(self, x):\n",
        "        users = self.user_factors(x[:,0])\n",
        "        movies = self.movie_factors(x[:,1])\n",
        "        return sigmoid_range((users * movies).sum(dim=1), *self.y_range)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQGVCG1iJJ4q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UQOMRMRJJ4r"
      },
      "source": [
        "class DotProductBias(Module):\n",
        "    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
        "        self.user_factors = Embedding(n_users, n_factors)\n",
        "        self.user_bias = Embedding(n_users, 1)\n",
        "        self.movie_factors = Embedding(n_movies, n_factors)\n",
        "        self.movie_bias = Embedding(n_movies, 1)\n",
        "        self.y_range = y_range\n",
        "        \n",
        "    def forward(self, x):\n",
        "        users = self.user_factors(x[:,0])\n",
        "        movies = self.movie_factors(x[:,1])\n",
        "        res = (users * movies).sum(dim=1, keepdim=True)\n",
        "        res += self.user_bias(x[:,0]) + self.movie_bias(x[:,1])\n",
        "        return sigmoid_range(res, *self.y_range)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rquS_hOJJJ4r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxqZwfttJJ4r"
      },
      "source": [
        "### Weight Decay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71TzWcfcJJ4s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgZykdx-JJ4s"
      },
      "source": [
        "### Creating Our Own Embedding Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fTl2d3PJJ4s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD2czK6xJJ4s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIpWINv5JJ4s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3SRu1WhJJ4s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5hy_lGLJJ4t"
      },
      "source": [
        "def create_params(size):\n",
        "    return nn.Parameter(torch.zeros(*size).normal_(0, 0.01))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovt5vtQJJJ4t"
      },
      "source": [
        "class DotProductBias(Module):\n",
        "    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
        "        self.user_factors = create_params([n_users, n_factors])\n",
        "        self.user_bias = create_params([n_users])\n",
        "        self.movie_factors = create_params([n_movies, n_factors])\n",
        "        self.movie_bias = create_params([n_movies])\n",
        "        self.y_range = y_range\n",
        "        \n",
        "    def forward(self, x):\n",
        "        users = self.user_factors[x[:,0]]\n",
        "        movies = self.movie_factors[x[:,1]]\n",
        "        res = (users*movies).sum(dim=1)\n",
        "        res += self.user_bias[x[:,0]] + self.movie_bias[x[:,1]]\n",
        "        return sigmoid_range(res, *self.y_range)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBwfqDAoJJ4t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvJSVISKJJ4t"
      },
      "source": [
        "## Interpreting Embeddings and Biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcMyZcDiJJ4t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaS6BceHJJ4t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkuVF6RyJJ4u"
      },
      "source": [
        "### Using fastai.collab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA78swc-JJ4u"
      },
      "source": [
        "learn = collab_learner(dls, n_factors=50, y_range=(0, 5.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st1GUyCSJJ4u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvQnLVx7JJ4u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9wwX9zdJJ4u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3w9I8DyJJ4u"
      },
      "source": [
        "### Embedding Distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQB0mys4JJ4u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6-3ssaWJJ4v"
      },
      "source": [
        "## Bootstrapping a Collaborative Filtering Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdbipf6fJJ4v"
      },
      "source": [
        "## Deep Learning for Collaborative Filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRdx_7wNJJ4v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKNUxcBzJJ4v"
      },
      "source": [
        "class CollabNN(Module):\n",
        "    def __init__(self, user_sz, item_sz, y_range=(0,5.5), n_act=100):\n",
        "        self.user_factors = Embedding(*user_sz)\n",
        "        self.item_factors = Embedding(*item_sz)\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(user_sz[1]+item_sz[1], n_act),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_act, 1))\n",
        "        self.y_range = y_range\n",
        "        \n",
        "    def forward(self, x):\n",
        "        embs = self.user_factors(x[:,0]),self.item_factors(x[:,1])\n",
        "        x = self.layers(torch.cat(embs, dim=1))\n",
        "        return sigmoid_range(x, *self.y_range)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyAjlNfzJJ4v"
      },
      "source": [
        "model = CollabNN(*embs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9_ERTXNJJ4v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41-CxGeoJJ4w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbpKUTO5JJ4w"
      },
      "source": [
        "@delegates(TabularModel)\n",
        "class EmbeddingNN(TabularModel):\n",
        "    def __init__(self, emb_szs, layers, **kwargs):\n",
        "        super().__init__(emb_szs, layers=layers, n_cont=0, out_sz=1, **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8E4lXGkJJ4w"
      },
      "source": [
        "### Sidebar: kwargs and Delegates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5mt2XahJJ4w"
      },
      "source": [
        "### End sidebar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6ewEit8JJ4w"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLcQS4igJJ4w"
      },
      "source": [
        "## Questionnaire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddq70qk8JJ4w"
      },
      "source": [
        "1. What problem does collaborative filtering solve?\n",
        "1. How does it solve it?\n",
        "1. Why might a collaborative filtering predictive model fail to be a very useful recommendation system?\n",
        "1. What does a crosstab representation of collaborative filtering data look like?\n",
        "1. Write the code to create a crosstab representation of the MovieLens data (you might need to do some web searching!).\n",
        "1. What is a latent factor? Why is it \"latent\"?\n",
        "1. What is a dot product? Calculate a dot product manually using pure Python with lists.\n",
        "1. What does `pandas.DataFrame.merge` do?\n",
        "1. What is an embedding matrix?\n",
        "1. What is the relationship between an embedding and a matrix of one-hot-encoded vectors?\n",
        "1. Why do we need `Embedding` if we could use one-hot-encoded vectors for the same thing?\n",
        "1. What does an embedding contain before we start training (assuming we're not using a pretained model)?\n",
        "1. Create a class (without peeking, if possible!) and use it.\n",
        "1. What does `x[:,0]` return?\n",
        "1. Rewrite the `DotProduct` class (without peeking, if possible!) and train a model with it.\n",
        "1. What is a good loss function to use for MovieLens? Why? \n",
        "1. What would happen if we used cross-entropy loss with MovieLens? How would we need to change the model?\n",
        "1. What is the use of bias in a dot product model?\n",
        "1. What is another name for weight decay?\n",
        "1. Write the equation for weight decay (without peeking!).\n",
        "1. Write the equation for the gradient of weight decay. Why does it help reduce weights?\n",
        "1. Why does reducing weights lead to better generalization?\n",
        "1. What does `argsort` do in PyTorch?\n",
        "1. Does sorting the movie biases give the same result as averaging overall movie ratings by movie? Why/why not?\n",
        "1. How do you print the names and details of the layers in a model?\n",
        "1. What is the \"bootstrapping problem\" in collaborative filtering?\n",
        "1. How could you deal with the bootstrapping problem for new users? For new movies?\n",
        "1. How can feedback loops impact collaborative filtering systems?\n",
        "1. When using a neural network in collaborative filtering, why can we have different numbers of factors for movies and users?\n",
        "1. Why is there an `nn.Sequential` in the `CollabNN` model?\n",
        "1. What kind of model should we use if we want to add metadata about users and items, or information such as date and time, to a collaborative filtering model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u53a92AmJJ4x"
      },
      "source": [
        "### Further Research\n",
        "\n",
        "1. Take a look at all the differences between the `Embedding` version of `DotProductBias` and the `create_params` version, and try to understand why each of those changes is required. If you're not sure, try reverting each change to see what happens. (NB: even the type of brackets used in `forward` has changed!)\n",
        "1. Find three other areas where collaborative filtering is being used, and find out what the pros and cons of this approach are in those areas.\n",
        "1. Complete this notebook using the full MovieLens dataset, and compare your results to online benchmarks. See if you can improve your accuracy. Look on the book's website and the fast.ai forum for ideas. Note that there are more columns in the full dataset—see if you can use those too (the next chapter might give you ideas).\n",
        "1. Create a model for MovieLens that works with cross-entropy loss, and compare it to the model in this chapter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww9RsKkZJJ4y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}