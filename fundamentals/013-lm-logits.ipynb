{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"013-lm-logits.ipynb","provenance":[{"file_id":"https://github.com/Calvin-CS344-21SP/ai-portfolio-sudonotdisturb/blob/main/fundamentals/013-lm-logits.ipynb","timestamp":1618242863729}],"collapsed_sections":["e_eu5NsC4m0Z"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"85e6a924a32e484d89d7bc56950e604b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8dc9e5a6d21b4b12afc1bdbd3f7fb2d7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_228833b3cae24c51a61026d2d5456c6c","IPY_MODEL_3e46f44c581b48d1b8d0438349f7bc34"]}},"8dc9e5a6d21b4b12afc1bdbd3f7fb2d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"228833b3cae24c51a61026d2d5456c6c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7b3de86606854f3dbf66b0784b70ff9c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":762,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":762,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_03869116b36b432ba9c5de880083548e"}},"3e46f44c581b48d1b8d0438349f7bc34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3607750c7be140668550da31ce484ca7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 762/762 [01:39&lt;00:00, 7.68B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_596098eb7d38415e934a2c1d6ad70f13"}},"7b3de86606854f3dbf66b0784b70ff9c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"03869116b36b432ba9c5de880083548e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3607750c7be140668550da31ce484ca7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"596098eb7d38415e934a2c1d6ad70f13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5787c7a68b674c589aa64e2e47ae12f1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d4121cd22e664ad791577b500070fc6a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_61a0d2aec66340f9ae1758254692689b","IPY_MODEL_91d01e1379cf499388c262cc01a40940"]}},"d4121cd22e664ad791577b500070fc6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"61a0d2aec66340f9ae1758254692689b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_765a8c8c28b446a0a30c738f950c3f52","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1042301,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1042301,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e61e7df10ff745b3aeedd638fad340c3"}},"91d01e1379cf499388c262cc01a40940":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a39534361fd644388c70bc5f86daeac8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.04M/1.04M [00:01&lt;00:00, 586kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_91fd72f2160747f4a83541d6d3177002"}},"765a8c8c28b446a0a30c738f950c3f52":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e61e7df10ff745b3aeedd638fad340c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a39534361fd644388c70bc5f86daeac8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"91fd72f2160747f4a83541d6d3177002":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bdbbd74f89bd44fab4b1dca2bab112fc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1e7808e1ebb44c4889d7ee5ffc1dd24c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bdb9d61b793e46d9a2bf01f69d7cd903","IPY_MODEL_86f9add145b945bdaf2e28b1f27aa44f"]}},"1e7808e1ebb44c4889d7ee5ffc1dd24c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bdb9d61b793e46d9a2bf01f69d7cd903":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3d7d8caf9961453faee724e7002509a8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5dde458375fe4da79d8f4d08c75198c4"}},"86f9add145b945bdaf2e28b1f27aa44f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_63a68ecc639f492897c4d10b9cd08006","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:00&lt;00:00, 465kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8b2e33e04fdc4049874e6348340be872"}},"3d7d8caf9961453faee724e7002509a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5dde458375fe4da79d8f4d08c75198c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"63a68ecc639f492897c4d10b9cd08006":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8b2e33e04fdc4049874e6348340be872":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c6fe94900f0c4476af795185ade2052a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_86727188035f443485aa96d1611e9e20","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5c331c9cfffe4d78b1ef92cb764f8354","IPY_MODEL_ae31487bd917472e9c8ad64f9eeee658"]}},"86727188035f443485aa96d1611e9e20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c331c9cfffe4d78b1ef92cb764f8354":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7c3d79bf7b1f4e419aad6d68aaf977b4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1355256,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355256,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_92b3f17f86ca40ccaed41babd210c440"}},"ae31487bd917472e9c8ad64f9eeee658":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b8f07975970447c79569b8698baf097e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [01:37&lt;00:00, 13.9kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_82262d27574c482194950ded63d686e5"}},"7c3d79bf7b1f4e419aad6d68aaf977b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"92b3f17f86ca40ccaed41babd210c440":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b8f07975970447c79569b8698baf097e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"82262d27574c482194950ded63d686e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c44cd4fa99384af0ae3cd617936e2685":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6e6324040ee14e63b6de2c11c227b448","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_58047b03deb34bb4bfe7a18126106bbc","IPY_MODEL_58051b5de8c74d1c8db7f005d605f256"]}},"6e6324040ee14e63b6de2c11c227b448":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"58047b03deb34bb4bfe7a18126106bbc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_629d29742ba541b68822813b1fab6ebb","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":352833716,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":352833716,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b842a609ae4a434892b809efa3b9f02a"}},"58051b5de8c74d1c8db7f005d605f256":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_db27157f1afe499097fd027e24c4c50a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 353M/353M [01:34&lt;00:00, 3.72MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_951bd462edbe4564948e533b6b76fc55"}},"629d29742ba541b68822813b1fab6ebb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b842a609ae4a434892b809efa3b9f02a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"db27157f1afe499097fd027e24c4c50a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"951bd462edbe4564948e533b6b76fc55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"3jc8Qlh1TEgC"},"source":["# `013` Language Models and Logits\n","\n","Task: Ask a language model for the most likely next tokens.\n","\n","This notebook follows up on `012-tokenization`."]},{"cell_type":"markdown","metadata":{"id":"f8_8RWp3TX-8"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"aUvTIxyWTdBF"},"source":["We'll be using the HuggingFace Transformers library, which provides a (mostly) consistent interface to many different language models. We'll focus on the OpenAI GPT-2 model, famous for OpenAI's assertion that it was \"too dangerous\" to release in full.\n","\n","[Documentation](https://huggingface.co/transformers/model_doc/gpt2.html) for the model and tokenizer."]},{"cell_type":"code","metadata":{"id":"vWy--2nwhWPy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618242927410,"user_tz":240,"elapsed":9441,"user":{"displayName":"Zachary Chin","photoUrl":"","userId":"00634451652335778717"}},"outputId":"47ff977f-2211-456c-b012-076b04d4b6a9"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/91/61d69d58a1af1bd81d9ca9d62c90a6de3ab80d77f27c5df65d9a2c1f5626/transformers-4.5.0-py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.2MB 6.7MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 28.1MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n","\u001b[K     |████████████████████████████████| 870kB 28.9MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=0ae5ef7901b56c723d6e2b50464c066cbea5ab83a942265b003894079b3df251\n","  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.5.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"osKgPaDwhaN4"},"source":["import torch\n","from torch import tensor"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UiNKbIh8hyDg"},"source":["### Download and load the model"]},{"cell_type":"code","metadata":{"id":"IM5o_4w1hfyV","colab":{"base_uri":"https://localhost:8080/","height":262,"referenced_widgets":["85e6a924a32e484d89d7bc56950e604b","8dc9e5a6d21b4b12afc1bdbd3f7fb2d7","228833b3cae24c51a61026d2d5456c6c","3e46f44c581b48d1b8d0438349f7bc34","7b3de86606854f3dbf66b0784b70ff9c","03869116b36b432ba9c5de880083548e","3607750c7be140668550da31ce484ca7","596098eb7d38415e934a2c1d6ad70f13","5787c7a68b674c589aa64e2e47ae12f1","d4121cd22e664ad791577b500070fc6a","61a0d2aec66340f9ae1758254692689b","91d01e1379cf499388c262cc01a40940","765a8c8c28b446a0a30c738f950c3f52","e61e7df10ff745b3aeedd638fad340c3","a39534361fd644388c70bc5f86daeac8","91fd72f2160747f4a83541d6d3177002","bdbbd74f89bd44fab4b1dca2bab112fc","1e7808e1ebb44c4889d7ee5ffc1dd24c","bdb9d61b793e46d9a2bf01f69d7cd903","86f9add145b945bdaf2e28b1f27aa44f","3d7d8caf9961453faee724e7002509a8","5dde458375fe4da79d8f4d08c75198c4","63a68ecc639f492897c4d10b9cd08006","8b2e33e04fdc4049874e6348340be872","c6fe94900f0c4476af795185ade2052a","86727188035f443485aa96d1611e9e20","5c331c9cfffe4d78b1ef92cb764f8354","ae31487bd917472e9c8ad64f9eeee658","7c3d79bf7b1f4e419aad6d68aaf977b4","92b3f17f86ca40ccaed41babd210c440","b8f07975970447c79569b8698baf097e","82262d27574c482194950ded63d686e5","c44cd4fa99384af0ae3cd617936e2685","6e6324040ee14e63b6de2c11c227b448","58047b03deb34bb4bfe7a18126106bbc","58051b5de8c74d1c8db7f005d605f256","629d29742ba541b68822813b1fab6ebb","b842a609ae4a434892b809efa3b9f02a","db27157f1afe499097fd027e24c4c50a","951bd462edbe4564948e533b6b76fc55"]},"executionInfo":{"status":"ok","timestamp":1618242948443,"user_tz":240,"elapsed":24548,"user":{"displayName":"Zachary Chin","photoUrl":"","userId":"00634451652335778717"}},"outputId":"22778018-5eab-4a1f-808f-94037798ae5d"},"source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\", add_prefix_space=True) # smaller version of GPT-2\n","# Alternative to add_prefix_space is to use `is_split_into_words=True`\n","# add the EOS token as PAD token to avoid warnings\n","model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\", pad_token_id=tokenizer.eos_token_id)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"85e6a924a32e484d89d7bc56950e604b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=762.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5787c7a68b674c589aa64e2e47ae12f1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bdbbd74f89bd44fab4b1dca2bab112fc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6fe94900f0c4476af795185ade2052a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355256.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c44cd4fa99384af0ae3cd617936e2685","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=352833716.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m-Z9_U0LUEVQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618242948828,"user_tz":240,"elapsed":364,"user":{"displayName":"Zachary Chin","photoUrl":"","userId":"00634451652335778717"}},"outputId":"2f5d57ea-26d1-4176-c8b4-9da3ef3932a7"},"source":["print(f\"The model has {model.num_parameters():,d} parameters.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The model has 81,912,576 parameters.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OOUiz_PsUZgS"},"source":["## Task\n","\n","Consider the following phrase: \"This weekend I plan to\".\n","\n","1. Convert the phrase into token ids.\n","2. Use the `forward` method of the `model`. Explain the shape of `model_output.logits`.\n","3. Pull out the logits corresponding to the *last* token in the input phrase. Identify the id of the most likely next token.\n","4. Find what token the model thinks is the most likely.\n","5. Use the `topk` method to find the top-20 most likely choices for the next token. \n","6. Write a function that is given a phrase and a *k* and returns the top *k* most likely next tokens."]},{"cell_type":"code","metadata":{"id":"JS7Z-DjoUiLK"},"source":["#phrase = \"In a shocking finding, scientists discovered a herd of unicorns living in\"\n","phrase = \"This weekend I plan to\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e_eu5NsC4m0Z"},"source":["#### Convert phrase to token ids"]},{"cell_type":"code","metadata":{"id":"QpyeKakrjfpt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618244217014,"user_tz":240,"elapsed":248,"user":{"displayName":"Zachary Chin","photoUrl":"","userId":"00634451652335778717"}},"outputId":"ffab1e61-39f4-4319-a708-a7e8668bfca3"},"source":["input_ids = tokenizer.encode(phrase)\n","input_ids"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[770, 5041, 314, 1410, 284]"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"markdown","metadata":{"id":"FDKJ3_ln4rZV"},"source":["#### Use the `forward` method of the `model`"]},{"cell_type":"code","metadata":{"id":"ZEy1QBTDotjU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618244220415,"user_tz":240,"elapsed":332,"user":{"displayName":"Zachary Chin","photoUrl":"","userId":"00634451652335778717"}},"outputId":"c4c8d702-eba3-4031-af47-6c07a326fbc0"},"source":["model_output = model.forward(tensor([input_ids]))\n","model_output.logits.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 5, 50257])"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"markdown","metadata":{"id":"LuYipua0z5I4"},"source":["The shape of `model_output.logits`:\n","\n","* 1:: one batch\n","* 5:: five arrays of next-token-likelihoods for each token in the initial phrase.\n","* 50257:: the size of the vocabulary; each array contains the likelihoods of being the next token for each token in the vocabulary.\n"]},{"cell_type":"code","metadata":{"id":"2EHMGJFPS05B"},"source":["# since we only have a single sequence (batch size of 1), let's collapse the batch dimension.\n","logits = model_output.logits[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NtiZp6az44Cl"},"source":["#### Pull out the logits corresponding to the last token in the input phrase"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_uERt61S5OX5","executionInfo":{"status":"ok","timestamp":1618245254536,"user_tz":240,"elapsed":723,"user":{"displayName":"Zachary Chin","photoUrl":"","userId":"00634451652335778717"}},"outputId":"cbe72cbc-5f36-410c-9fe5-d50b722fc411"},"source":["last_token_logits = logits[-1]\n","last_token_logits"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-77.8725, -79.7684, -82.1183,  ..., -88.5235, -86.5615, -79.6716],\n","       grad_fn=<SelectBackward>)"]},"metadata":{"tags":[]},"execution_count":103}]},{"cell_type":"markdown","metadata":{"id":"U53a1bsa527f"},"source":["#### Identify the id of the most likely next token"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGKJJKvU54oS","executionInfo":{"status":"ok","timestamp":1618245655142,"user_tz":240,"elapsed":237,"user":{"displayName":"Zachary Chin","photoUrl":"","userId":"00634451652335778717"}},"outputId":"4b4dc00f-62a1-4535-81ac-7ba21cfe0c6f"},"source":["max_logit = last_token_logits.max()\n","most_likely_id = (last_token_logits == max_logit).nonzero(as_tuple=True)[0]\n","most_likely_id"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([467])"]},"metadata":{"tags":[]},"execution_count":124}]},{"cell_type":"markdown","metadata":{"id":"-uaQ680P5bsv"},"source":["#### Find what token the model thinks is the most likely"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"YVGUTZPx70ut","executionInfo":{"status":"ok","timestamp":1618245657917,"user_tz":240,"elapsed":335,"user":{"displayName":"Zachary Chin","photoUrl":"","userId":"00634451652335778717"}},"outputId":"52767c5e-fd4d-4681-9239-b0adac803290"},"source":["tokenizer.decode(most_likely_id)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' go'"]},"metadata":{"tags":[]},"execution_count":125}]},{"cell_type":"markdown","metadata":{"id":"ujoCzkVU5iE-"},"source":["#### Find the top-20 most likely choices for the next token"]},{"cell_type":"code","metadata":{"id":"kJWXqQLLkCyP","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1618245323667,"user_tz":240,"elapsed":245,"user":{"displayName":"Zachary Chin","photoUrl":"","userId":"00634451652335778717"}},"outputId":"ba5e8b3b-a4c0-4a3c-fce0-2f72304ff9cf"},"source":["top_tokens = last_token_logits.topk(k=20)\n","tokenizer.decode(top_tokens[1])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' go take spend make do be attend visit run have write play get start head travel try bring return share'"]},"metadata":{"tags":[]},"execution_count":110}]},{"cell_type":"markdown","metadata":{"id":"naWU2Ka-5nRT"},"source":["#### Write a function that is given a phrase and a k and returns the top k most likely next tokens"]},{"cell_type":"code","metadata":{"id":"xhL9qP4HpJlx","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1618244415351,"user_tz":240,"elapsed":277,"user":{"displayName":"Zachary Chin","photoUrl":"","userId":"00634451652335778717"}},"outputId":"caae0468-8b9a-4fd8-a961-c8123d2d0ba5"},"source":["def get_top_tokens(phrase, k):\n","  input_ids = tokenizer.encode(phrase)\n","  model_output = model.forward(tensor([input_ids]))\n","  top_tokens = model_output.logits[0][-1].topk(k=k)\n","  return tokenizer.decode(top_tokens[1])\n","\n","get_top_tokens(\"I wish I were\", 10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' a the more in there able here an on just'"]},"metadata":{"tags":[]},"execution_count":77}]},{"cell_type":"markdown","metadata":{"id":"PsI_Tz0ipglx"},"source":["## Analysis\n","\n","What would be required to generate more than one token? What decisions would you have to make?"]},{"cell_type":"markdown","metadata":{"id":"_NtjYCAd9WTp"},"source":["To generate more than one token, we would have to add a token onto the phrase and feed that phrase back into the model to generate more possible tokens. We would need to decide which token to append to the original phrase. This could be the token the model believes is the most likely choice, or it could be chosen randomly across the top *k* tokens. Either way, when we input the new phrase back into the model, the model will generate new tokens based on the last token we added."]}]}